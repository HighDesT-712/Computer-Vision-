import cv2
import numpy as np
from libreriascreadas import model as m1

YOLO_IMAGE_SIZE = 320  #320 x320 are the pixels that yolo algorithm is dealing with

image = cv2.imread("girl_face.jpg")
#cv2.imshow("YOlo algorithm", image)
#cv2.waitKey()

print(image.shape) # 450 height ,600 width, 3
original_width, original_height = image.shape[1], image.shape[0]

# 80 or 90 possible output classes
# 0 is person,  2 is car , 5 is bus ,  this are the ids, is because that is whats the neural network will return to us
classes  = ['car','person','bus']

neural_network = cv2.dnn.readNetFromDarknet("yolov3.cfg","yolov3.weights")
#define if using CPU or GPU, we choose CPU. #GPUis faster than  cpu, but is hard to manage
neural_network.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
neural_network.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

#transform image into BLOB,
#first, normalizing
blob = cv2.dnn.blobFromImage(image,1/255,(320,320),True, crop = False) #opencv is going to divide every single pixel intesity will be in the range[0,1]
#True is RGB to BGR., because open cv uses BGR
#print(blob.shape) #1,3,320,320 OSEA : 1,3 because blue green and red,320 vertically ,320 horizontally
neural_network.setInput(blob) #with this, the image elected it is going to be the input for the yolo network
layer_names = neural_network.getLayerNames()
#print(layer_names)
#output layers, the indices of the  output layers, starting with 1 and not with 0
#print(neural_network.getUnconnectedOutLayers())


output_names=[layer_names[index-1] for index in neural_network.getUnconnectedOutLayers()]
# if neural_network.getUnconnectedOutLayers() is a 2 dimensional array , the the code is
#  output_names=[layer_names[index[0]-1] for index in neural_network.getUnconnectedOutLayers()]
# print(output_names)

outputs = neural_network.forward(output_names) # 300,85 : 300 predicted bounding boxes,85 parameters or also called prediction vector
#print(outputs[1].shape)

#bblocations is bounding box  locations, predicted objects are indices alse called ids
predicted_objects , bbox_locations, class_label_ids, conf_values = m1.find_objects(outputs)

#original_width/YOLO_IMAGE_SIZE  is the ratio of width, this exists becuase the reescalation that we make in order to transform
#the image, into a 320x320 images, because that is the size that YOLO has been trained, with the yolov3.weight, and yolov3.cfg
m1.show_detected_images(image, predicted_objects, bbox_locations,class_label_ids,conf_values,original_width/YOLO_IMAGE_SIZE, original_height/YOLO_IMAGE_SIZE )

cv2.imshow("Yolo Algorithm", image)
cv2.waitKey()